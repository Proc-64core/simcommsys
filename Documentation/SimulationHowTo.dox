/*!
\file

Copyright (c) 2013 Johann A. Briffa

This file is part of SimCommSys.

SimCommSys is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

SimCommSys is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with SimCommSys.  If not, see <http://www.gnu.org/licenses/>.


\page simulation How to set up and run a simulation
\author   Stephan Wesemeyer

\todo Update instructions according to current scripts.

\todo Move necessary scripts, libraries, and templates into the simcommsys
folder and update the documentation accordingly.


\section assumptions Assumptions

-# You have a working svn directory:/path_to_svn_dir/ with the following
   projects checked out
   - Projects/ECW
   - Programming
   - Scripts


\section prereq Prerequisites

-# Ensure that the ECW, Programming and Scripts folders are up to date by using
   svn up in each of them
-# Ensure that you have /path_to_svn_dir/Scripts/Python, SimCommsys and Condor
   in your search path, e.g. add
\verbatim
#add the Python folder to my Path
PATH="/path_to_svn_dir/Scripts/Python:/path_to_svn_dir/Scripts/SimCommsys:
/path_to_svn_dir/Scripts/Condor:$PATH"
\endverbatim
   to the .bashrc file in your home directory.
-# In Programming/branches/yourBranch run
\verbatim
make install
\endverbatim
   This will create a bin.Arch/ directory in your home directory
   containing the binaries for your CPU architecture (eg bin.x86_64
   for 64-bit CPU/OS) within it the binaries adhere to the following
   naming convention: name.yourBranch.debug and name.yourBranch.release,
   e.g. simcommsys.jab.release.
-# Ensure you have bin.Arch in your search path, e.g. add
\verbatim
#add bin.i686 directory to my Path
PATH="$HOME/bin.i686:$PATH"
\endverbatim
   to the .profile file in your home directory


\section setup Set Up The Simulation

-# cd to /path_to/ECW/Results
-# Set up a new directory for your simulation by copying the provided template,
   e.g.
\verbatim
svn cp TemplateSimulation YourSimulation
\endverbatim
-# Copy the systems that you want to simulate into the Systems folder (either
   using svn cp if they are under version control or just cp and svn add if
   they are not)
-# Run the Makefile to ensure all the appropriate simulator files are created
   from the system files.
-# commit your files to svn


\section run Running the simulation locally

This section shows you how to run a simulation in client-server mode but
not on the cluster.
There are 2 simulation modes: abstract and conventional
-  "abstract" uses a logarithmic scale (ie the steps between simulations are
   obtained using a multiplier)
-  "conventional" uses a standard interval by which the values are
   increased/decreased.

\subsection abstract For "abstract" simulations

-# cd to YourSimulation/
-# run the following command to generate data points for a logarithmic scale
\verbatim
simulate-batch.sh abstract <tag> <port> "[<start> [<mult> [<end> [<floor> [<tol> [<conf>]]]]]]" systemName.txt
\endverbatim
   where:
   - abstract indicates a logarithmic scale
   - <tag> is the name of your branch, e.g. jab
   - <port> is the port number on which the server should listen
   .
   The parameters in quotes have some default values and hence can be omitted
   if the default is correct
   - <start>(0.5) : is the value from which the simulation should start
      (eg snr in dB or insertion/deletion probability)
   - <mult>(0.8) : is the value with which the simulator will multiply to
      obtain the next value at which to start a new simulation
   - <end>(1e-5) : is the end value at which the simulation will finish
      (unless the floor value has been reach previously)
   - <floor>(1e-5) : is the error level that once surpassed will actually
      terminate the simulation even if the end value has not been reached.
   - <tol>(0.20) : is the interval around the measured value in which the
      true result should lie
   - <conf>(0.80) : is the confidence level that the result lies within the
      tolerance interval
   .
   The tol and conf parameters determine how long the monte carlo simulation
   is going to run. The lower the tolerance interval and the higher the
   required confidence level is set the longer the simulation will need to
   run to achieve that. In order to obtain results that are publishable,
   these values should be set to tol=0.05 (ie the true result will be within
   +/-5% of the measured result) and conf=0.99 (ie we are 99% certain that
   the true result lies within that tolerance level).
   For tol=0.05 and conf=0.99, if the measure value is 1 then we are 99%
   confident that the true result is between 0.95 and 1.05.
   For quick and dirty results and hence quicker results which are still
   indicative the default values are acceptable.
   - systemName.txt is the name of the system to simulate which must be
      under the directory Simulators
-# You can now start as many client process as you have CPUs by executing:
\verbatim
simcommsys.<tag>.release -e localhost:<port>
\endverbatim
   where:
   - <tag> is the name of your branch, e.g. jab
   - <port> is the port number you specified in step 2

Note that the simulator runs in a screen session, type
\verbatim
screen -ls
\endverbatim
to check that a session is running and
\verbatim
screen -r <id>
\endverbatim
(where <id> is the screen session) to check it is running.

\subsection conventional For "conventional" simulations

-# cd to YourSimulation/
-# run the following command to generate data points for a logarithmic scale
\verbatim
simulate-batch.sh conventional <tag> <port> "[<start> [<step> [<end> [<floor> [<tol> [<conf>]]]]]]" systemName.txt
\endverbatim
   where:
   - conventional indicates a linear scale
   - <tag> is the name of your branch, e.g. jab
   - <port> is the port number on which the server should listen
   .
   The parameters in quotes have some default values and hence can be omitted
   if the default is correct
   - <start>(0.0) : is the value from which the simulation should start (eg SNR
      in dB or insertion/deletion probability)
   - <step>(0.25) : is the value which the simulator will add to obtain the next
      value at which to start a new simulation
   - <end>(3.0) : is the end value at which the simulation will finish (unless
      the floor value has been reach previously)
   - <floor>(1e-5) : is the error level that once surpassed will actually
      terminate the simulation even if the end value has not been reached.
   - <tol>(0.20) : is the interval around the measured value in which the true
      result should lie
   - <conf>(0.80) : is the confidence level that the result lies within the
      tolerance interval
   .
   The tol and conf parameters determine how long the monte carlo simulation
   is going to run. The lower the tolerance interval and the higher the
   required confidence level is set the longer the simulation will need to
   run to achieve that. In order to obtain results that are publishable,
   these values should be set to tol=0.05 (ie the true result will be within
   +/-5% of the measured result) and conf=0.99 (ie we are 99% certain that
   the true result lies within that tolerance level).
   For tol=0.05 and conf=0.99, if the measure value is 1 then we are 99%
   confident that the true result is between 0.95 and 1.05.
   For quick and dirty results and hence quicker results which are still
   indicative the default values are acceptable
   - systemName.txt is the name of the system to simulate which must be under
      the directory Simulators
-# You can now start as many client process as you have CPUs by executing:
\verbatim
simcommsys.<tag>.release -e localhost:<port>
\endverbatim
   where:
   - <tag> is the name of your branch, e.g. jab
   - <port> is the port number you specified in step 2

\section cluster Running the simulation on the cluster

\todo Update this to include information on the various cluster middleware
currently supported (Condor, Sun Grid Engine, Torque, etc)

The principles are the same as for the local simulation. The main difference
is the way the jobs are submitted and where the server and client processes
are located. The current convention is to run the server process on Hawker05
and the client processes on the cluster, through the job scheduler.
If there are multiple people running simulations you need to ensure that every
one is allocated a unique range of ports, e.g.
   - jab: 9999 - 9900
   - swe: 9899 - 9800
   - hgs: 9799 - 9700

Note that Hawker05 is i686 and the cluster is x86_64, so the source code needs
to be compiled & installed both on hawker05 and tempest101. As hawker05 and
tempest101 share the same home directories so everything that is available to
hawker05 is available to tempest101. Unfortunately, tempest101 does not have an
svn client, so any checkouts/commits need to be done on hawker05.

However, if you have another Linux desktop on the internal network, you share
the same home directory with hawker05 and tempest101. If you have done any
checkouts on your desktop machine, the likelihood is that your svn client is
more recent than the one used on hawker05. This might mean that hawker05 will
refuse to checkout files as the svn metadata was generated by a newer version of
the svn client. If this is the case, you can either use separate working folders
or just ensure that you only ever check code out on your desktop machine.

-# The server process on hawker is started exactly as before. Please ensure that
   you use the right port ranges allocated to you.
-# To start the clients on the cluster you need to ssh onto tempest101 which is
   the designated headnode of the cluster.
-# Ensure that you have the lastest binaries for tempest by executing make
   install on tempest.
-# You can now simply execute:
\verbatim
submit-simcommsys.sh <tag> <count> <host> <first port> [<last port>]
\endverbatim
   where:
   - <tag> should be something like stable-99 and refers to the appropriate
      release but might just be your branch name, e.g. jab
   - <count> is the number of processes you wish to start
   - <host> this is the host where the  server process is located, usually hawker05
   - <first port> is the first port on which the server process is listening
   - <last port> is the last port on which the server process is listening (note
      that <first port> must be less than <last port>)
   .
   So if you started a number of different server processes on hawker05
   which listen on consecutive ports in ascending order you can allocated
   the same number of clients to each of them with the above command.
   Most users will probably want to vary the number of clients per server
   process and hence will call submit-simcommsys.sh multiple times.

There are several commands that are useful to query/control the cluster:
-# condor_status gives an overview of how many CPUs the cluster has and whether
   they have been allocated to run any jobs
-# condor_q shows the current queues of jobs running on the cluster
-# condor_rm <user> removes all jobs owned by <user>
-# condor_rm <condor.proc> removes the given job

*/
